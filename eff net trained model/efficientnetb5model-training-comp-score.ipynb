{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016663,
     "end_time": "2020-10-06T10:26:03.456083",
     "exception": false,
     "start_time": "2020-10-06T10:26:03.439420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><h1>EffnetB5</h1></center>\n",
    "\n",
    "\n",
    "#### Commit 3\n",
    "- Epochs 100\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.385\n",
    "\n",
    "#### 4.65729455947876\n",
    "\n",
    "#### Commit 4\n",
    "- Epochs 120\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.385\n",
    "\n",
    "#### 4.658516883850098\n",
    "\n",
    "#### Commit 5\n",
    "- Epochs 100\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.38549\n",
    "- Save model cpt => min\n",
    "\n",
    "#### 4.656189918518066\n",
    "\n",
    "#### Commit 6\n",
    "- Epochs 100\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.0025\n",
    "- Dropout 0.38549\n",
    "- Save model cpt => min\n",
    "\n",
    "#### 4.654385757446289\n",
    "\n",
    "#### Commit 8\n",
    "- Epochs 150\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.36\n",
    "- Save model cpt => min\n",
    "\n",
    "#### 4.659050369262696\n",
    "\n",
    "#### Commit 9\n",
    "- Epochs 100\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.4\n",
    "- Save model cpt => min\n",
    "- 456x456\n",
    "\n",
    "#### 4.661175918579102\n",
    "\n",
    "#### Commit 10 (EffNet B6)\n",
    "- Epochs 100\n",
    "- Batch 3\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.43\n",
    "- Save model cpt => min\n",
    "- 540x540\n",
    "\n",
    "#### Commit 12 (EffNet B5)\n",
    "- Epochs 150\n",
    "- Batch 4\n",
    "- Folds 5\n",
    "- LR 0.003\n",
    "- Dropout 0.5\n",
    "- Save model cpt => min\n",
    "- 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:03.497220Z",
     "iopub.status.busy": "2020-10-06T10:26:03.496387Z",
     "iopub.status.idle": "2020-10-06T10:26:25.333578Z",
     "shell.execute_reply": "2020-10-06T10:26:25.332293Z"
    },
    "papermill": {
     "duration": 21.861139,
     "end_time": "2020-10-06T10:26:25.333752",
     "exception": false,
     "start_time": "2020-10-06T10:26:03.472613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/kerasapplications/keras-team-keras-applications-3b180cb\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.14.0)\r\n",
      "Building wheels for collected packages: Keras-Applications\r\n",
      "  Building wheel for Keras-Applications (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for Keras-Applications: filename=Keras_Applications-1.0.8-py3-none-any.whl size=50704 sha256=56a4a6aacec8e794485b29ba41c90d195eebc416037d773c1ce748899d589c48\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/96/13/eccdd9391bd8df958d78851b98ec4dc207ba05b67b011eb70a\r\n",
      "Successfully built Keras-Applications\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Looking in links: ./\r\n",
      "Processing /kaggle/input/efficientnet/efficientnet-1.1.0\r\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.16.2)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.18.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.2.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.4)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.8.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.14.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.2.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Building wheels for collected packages: efficientnet\r\n",
      "  Building wheel for efficientnet (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet: filename=efficientnet-1.1.0-py3-none-any.whl size=14141 sha256=ee71d91340f353e0484798f3133dc101b2bbef8548f13eb6fff464c4aaa6f0dc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/24/f5/31/3cc20871288fe532128224a3f5af7b4d67efb9835bd5683522\r\n",
      "Successfully built efficientnet\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/kerasapplications/keras-team-keras-applications-3b180cb -f ./ --no-index\n",
    "!pip install ../input/efficientnet/efficientnet-1.1.0/ -f ./ --no-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:25.401150Z",
     "iopub.status.busy": "2020-10-06T10:26:25.398253Z",
     "iopub.status.idle": "2020-10-06T10:26:32.398408Z",
     "shell.execute_reply": "2020-10-06T10:26:32.397318Z"
    },
    "papermill": {
     "duration": 7.035457,
     "end_time": "2020-10-06T10:26:32.398528",
     "exception": false,
     "start_time": "2020-10-06T10:26:25.363071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm \n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, Add, Conv2D, AveragePooling2D, \n",
    "    LeakyReLU, Concatenate \n",
    ")\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as tfa\n",
    "import efficientnet.tfkeras as efn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:32.456974Z",
     "iopub.status.busy": "2020-10-06T10:26:32.456166Z",
     "iopub.status.idle": "2020-10-06T10:26:34.987166Z",
     "shell.execute_reply": "2020-10-06T10:26:34.986501Z"
    },
    "papermill": {
     "duration": 2.562096,
     "end_time": "2020-10-06T10:26:34.987328",
     "exception": false,
     "start_time": "2020-10-06T10:26:32.425232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027042,
     "end_time": "2020-10-06T10:26:35.042157",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.015115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Parameters\n",
    "\n",
    "- `EPOCHS`: number of epochs to train for in each fold\n",
    "- `BATCH_SIZE`: batch size of images during training\n",
    "- `NFOLD`: number of folds in K-fold cross-validation (CV)\n",
    "- `LR`: learning rate\n",
    "- `SAVE_BEST`: default is True to save best weights on validation loss\n",
    "- `MODEL_CLASS`: the class of model. E.g. \"b1\" for EfficientNet-B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.104531Z",
     "iopub.status.busy": "2020-10-06T10:26:35.102439Z",
     "iopub.status.idle": "2020-10-06T10:26:35.105323Z",
     "shell.execute_reply": "2020-10-06T10:26:35.105880Z"
    },
    "papermill": {
     "duration": 0.036113,
     "end_time": "2020-10-06T10:26:35.106009",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.069896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "BATCH_SIZE = 4\n",
    "NFOLD = 5\n",
    "LR = 0.003\n",
    "SAVE_BEST = True\n",
    "MODEL_CLASS = 'b5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.167373Z",
     "iopub.status.busy": "2020-10-06T10:26:35.166405Z",
     "iopub.status.idle": "2020-10-06T10:26:35.179770Z",
     "shell.execute_reply": "2020-10-06T10:26:35.179163Z"
    },
    "papermill": {
     "duration": 0.046516,
     "end_time": "2020-10-06T10:26:35.179895",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.133379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.250599Z",
     "iopub.status.busy": "2020-10-06T10:26:35.249913Z",
     "iopub.status.idle": "2020-10-06T10:26:35.261459Z",
     "shell.execute_reply": "2020-10-06T10:26:35.262071Z"
    },
    "papermill": {
     "duration": 0.054631,
     "end_time": "2020-10-06T10:26:35.262215",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.207584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.328254Z",
     "iopub.status.busy": "2020-10-06T10:26:35.325754Z",
     "iopub.status.idle": "2020-10-06T10:26:35.331568Z",
     "shell.execute_reply": "2020-10-06T10:26:35.332086Z"
    },
    "papermill": {
     "duration": 0.039498,
     "end_time": "2020-10-06T10:26:35.332200",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.292702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.399780Z",
     "iopub.status.busy": "2020-10-06T10:26:35.397831Z",
     "iopub.status.idle": "2020-10-06T10:26:35.400420Z",
     "shell.execute_reply": "2020-10-06T10:26:35.400904Z"
    },
    "papermill": {
     "duration": 0.040916,
     "end_time": "2020-10-06T10:26:35.401024",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.360108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'Male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.464184Z",
     "iopub.status.busy": "2020-10-06T10:26:35.463316Z",
     "iopub.status.idle": "2020-10-06T10:26:35.789511Z",
     "shell.execute_reply": "2020-10-06T10:26:35.785659Z"
    },
    "papermill": {
     "duration": 0.361112,
     "end_time": "2020-10-06T10:26:35.789701",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.428589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077944019f2e44e690f7930d0e9b2f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())):\n",
    "    sub = train.loc[train.Patient == p, :] \n",
    "    fvc = sub.FVC.values\n",
    "    weeks = sub.Weeks.values\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0]\n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.860767Z",
     "iopub.status.busy": "2020-10-06T10:26:35.859870Z",
     "iopub.status.idle": "2020-10-06T10:26:35.862800Z",
     "shell.execute_reply": "2020-10-06T10:26:35.863435Z"
    },
    "papermill": {
     "duration": 0.041329,
     "end_time": "2020-10-06T10:26:35.863581",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.822252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    d = pydicom.dcmread(path)\n",
    "    return cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:26:35.938230Z",
     "iopub.status.busy": "2020-10-06T10:26:35.937277Z",
     "iopub.status.idle": "2020-10-06T10:28:26.381803Z",
     "shell.execute_reply": "2020-10-06T10:28:26.381160Z"
    },
    "papermill": {
     "duration": 110.485683,
     "end_time": "2020-10-06T10:28:26.381939",
     "exception": false,
     "start_time": "2020-10-06T10:26:35.896256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea2384d4841468b84f90dcadff5858a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = [], []\n",
    "for p in tqdm(train.Patient.unique()):\n",
    "    try:\n",
    "        ldir = os.listdir(f'../input/osic-pulmonary-fibrosis-progression-lungs-mask/mask_noise/mask_noise/{p}/')\n",
    "        numb = [float(i[:-4]) for i in ldir]\n",
    "        for i in ldir:\n",
    "            x.append(cv2.imread(f'../input/osic-pulmonary-fibrosis-progression-lungs-mask/mask_noise/mask_noise/{p}/{i}', 0).mean())\n",
    "            y.append(float(i[:-4]) / max(numb))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:28:26.478427Z",
     "iopub.status.busy": "2020-10-06T10:28:26.476391Z",
     "iopub.status.idle": "2020-10-06T10:28:26.479162Z",
     "shell.execute_reply": "2020-10-06T10:28:26.479615Z"
    },
    "papermill": {
     "duration": 0.066714,
     "end_time": "2020-10-06T10:28:26.479767",
     "exception": false,
     "start_time": "2020-10-06T10:28:26.413053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size=BATCH_SIZE):\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'../input/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size)\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0]\n",
    "                img = get_img(f'../input/osic-pulmonary-fibrosis-progression/train/{k}/{i}')\n",
    "                x.append(img)\n",
    "                a.append(self.a[k])\n",
    "                tab.append(self.tab[k])\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab)\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:28:26.571264Z",
     "iopub.status.busy": "2020-10-06T10:28:26.551986Z",
     "iopub.status.idle": "2020-10-06T10:28:26.575576Z",
     "shell.execute_reply": "2020-10-06T10:28:26.575049Z"
    },
    "papermill": {
     "duration": 0.066532,
     "end_time": "2020-10-06T10:28:26.575726",
     "exception": false,
     "start_time": "2020-10-06T10:28:26.509194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,))\n",
    "    x2 = tf.keras.layers.GaussianNoise(0.2)(inp2)\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model\n",
    "\n",
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype='float32')\n",
    "def score_loss():\n",
    "    def loss(y_true, y_pred):\n",
    "        tf.dtypes.cast(y_true, tf.float32)\n",
    "        tf.dtypes.cast(y_pred, tf.float32)\n",
    "        sigma_clip = C1\n",
    "        delta = tf.abs(y_true - y_pred)\n",
    "        sq2 = tf.sqrt(tf.dtypes.cast(2, dtype=tf.float32))\n",
    "        metric = (delta/sigma_clip)*sq2+tf.math.log(sigma_clip*sq2)\n",
    "        return K.mean(metric)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029001,
     "end_time": "2020-10-06T10:28:26.633510",
     "exception": false,
     "start_time": "2020-10-06T10:28:26.604509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T10:28:26.706504Z",
     "iopub.status.busy": "2020-10-06T10:28:26.699699Z",
     "iopub.status.idle": "2020-10-06T14:23:36.047574Z",
     "shell.execute_reply": "2020-10-06T14:23:36.046885Z"
    },
    "papermill": {
     "duration": 14109.386463,
     "end_time": "2020-10-06T14:23:36.048561",
     "exception": false,
     "start_time": "2020-10-06T10:28:26.662098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "####### Fold 0 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6954\n",
      "Epoch 00001: val_loss improved from inf to 16.96605, saving model to fold-0.h5\n",
      "32/32 [==============================] - 23s 715ms/step - loss: 4.6954 - val_loss: 16.9660\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6895\n",
      "Epoch 00002: val_loss did not improve from 16.96605\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6895 - val_loss: 65.8782\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6652\n",
      "Epoch 00003: val_loss improved from 16.96605 to 7.82879, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 626ms/step - loss: 4.6652 - val_loss: 7.8288\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6744\n",
      "Epoch 00004: val_loss improved from 7.82879 to 4.68810, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 623ms/step - loss: 4.6744 - val_loss: 4.6881\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6901\n",
      "Epoch 00005: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6901 - val_loss: 4.6959\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00006: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6808 - val_loss: 4.7210\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6850\n",
      "Epoch 00007: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6850 - val_loss: 4.6883\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 00008: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6794 - val_loss: 4.6907\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00009: val_loss did not improve from 4.68810\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6886 - val_loss: 4.7113\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00010: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6803 - val_loss: 4.7158\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6755\n",
      "Epoch 00011: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6755 - val_loss: 4.6892\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00012: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6769 - val_loss: 4.6898\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6861\n",
      "Epoch 00013: val_loss did not improve from 4.68810\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6861 - val_loss: 4.7217\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6907\n",
      "Epoch 00014: val_loss did not improve from 4.68810\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6907 - val_loss: 4.6903\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6889\n",
      "Epoch 00015: val_loss improved from 4.68810 to 4.68512, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6889 - val_loss: 4.6851\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6739\n",
      "Epoch 00016: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6739 - val_loss: 4.6945\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6814\n",
      "Epoch 00017: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6814 - val_loss: 4.6990\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6739\n",
      "Epoch 00018: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6739 - val_loss: 4.6947\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6738\n",
      "Epoch 00019: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6738 - val_loss: 4.7039\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6708\n",
      "Epoch 00020: val_loss did not improve from 4.68512\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6708 - val_loss: 4.6991\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6869\n",
      "Epoch 00021: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6869 - val_loss: 4.6983\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6749\n",
      "Epoch 00022: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6749 - val_loss: 4.6980\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6664\n",
      "Epoch 00023: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6664 - val_loss: 4.7123\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6708\n",
      "Epoch 00024: val_loss did not improve from 4.68512\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6708 - val_loss: 4.6960\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6826\n",
      "Epoch 00025: val_loss improved from 4.68512 to 4.67786, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 626ms/step - loss: 4.6826 - val_loss: 4.6779\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6798\n",
      "Epoch 00026: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6798 - val_loss: 4.6947\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6869\n",
      "Epoch 00027: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6869 - val_loss: 4.7037\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6815\n",
      "Epoch 00028: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6815 - val_loss: 4.6987\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6864\n",
      "Epoch 00029: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6864 - val_loss: 4.6876\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6737\n",
      "Epoch 00030: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6737 - val_loss: 4.6925\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00031: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6797 - val_loss: 4.6954\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6709\n",
      "Epoch 00032: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6709 - val_loss: 4.7032\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6757\n",
      "Epoch 00033: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6757 - val_loss: 4.6957\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6760\n",
      "Epoch 00034: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6760 - val_loss: 4.6817\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6698\n",
      "Epoch 00035: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6698 - val_loss: 4.6990\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6902\n",
      "Epoch 00036: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6902 - val_loss: 4.7127\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6805\n",
      "Epoch 00037: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6805 - val_loss: 4.6941\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6891\n",
      "Epoch 00038: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6891 - val_loss: 4.7096\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6716\n",
      "Epoch 00039: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6716 - val_loss: 4.7046\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6723\n",
      "Epoch 00040: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6723 - val_loss: 4.7212\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6855\n",
      "Epoch 00041: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6855 - val_loss: 4.7003\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6742\n",
      "Epoch 00042: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6742 - val_loss: 4.6841\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6788\n",
      "Epoch 00043: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6788 - val_loss: 4.7011\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6903\n",
      "Epoch 00044: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6903 - val_loss: 4.6923\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00045: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6886 - val_loss: 4.6937\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6765\n",
      "Epoch 00046: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6765 - val_loss: 4.7212\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6703\n",
      "Epoch 00047: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6703 - val_loss: 4.6837\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6770\n",
      "Epoch 00048: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6770 - val_loss: 4.7009\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6799\n",
      "Epoch 00049: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6799 - val_loss: 4.6834\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6839\n",
      "Epoch 00050: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6839 - val_loss: 4.6978\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6827\n",
      "Epoch 00051: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6827 - val_loss: 4.7131\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6826\n",
      "Epoch 00052: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6826 - val_loss: 4.7004\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00053: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6809 - val_loss: 4.6862\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6765\n",
      "Epoch 00054: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6765 - val_loss: 4.7028\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6704\n",
      "Epoch 00055: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6704 - val_loss: 4.6954\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00056: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6724 - val_loss: 4.6970\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6743\n",
      "Epoch 00057: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6743 - val_loss: 4.6961\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6849\n",
      "Epoch 00058: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6849 - val_loss: 4.7068\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6770\n",
      "Epoch 00059: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6770 - val_loss: 4.6983\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6632\n",
      "Epoch 00060: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6632 - val_loss: 4.7037\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00061: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6803 - val_loss: 4.7035\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6761\n",
      "Epoch 00062: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6761 - val_loss: 4.7209\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6747\n",
      "Epoch 00063: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6747 - val_loss: 4.6781\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6758\n",
      "Epoch 00064: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6758 - val_loss: 4.6822\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6689\n",
      "Epoch 00065: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6689 - val_loss: 4.6935\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6736\n",
      "Epoch 00066: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6736 - val_loss: 4.7010\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00067: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6818 - val_loss: 4.7079\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6678\n",
      "Epoch 00068: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.6678 - val_loss: 4.7146\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6816\n",
      "Epoch 00069: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6816 - val_loss: 4.6844\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6727\n",
      "Epoch 00070: val_loss did not improve from 4.67786\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6727 - val_loss: 4.7010\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6750\n",
      "Epoch 00071: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6750 - val_loss: 4.6900\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6871\n",
      "Epoch 00072: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6871 - val_loss: 4.7133\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6733\n",
      "Epoch 00073: val_loss did not improve from 4.67786\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6733 - val_loss: 4.6842\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6633\n",
      "Epoch 00074: val_loss improved from 4.67786 to 4.67747, saving model to fold-0.h5\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 4.6633 - val_loss: 4.6775\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6807\n",
      "Epoch 00075: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6807 - val_loss: 4.7100\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6697\n",
      "Epoch 00076: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6697 - val_loss: 4.6963\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6722\n",
      "Epoch 00077: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6722 - val_loss: 4.6870\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6912\n",
      "Epoch 00078: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6912 - val_loss: 4.6828\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00079: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6786 - val_loss: 4.7019\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00080: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6803 - val_loss: 4.7033\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6764\n",
      "Epoch 00081: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6764 - val_loss: 4.6918\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6653\n",
      "Epoch 00082: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6653 - val_loss: 4.6904\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6829\n",
      "Epoch 00083: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6829 - val_loss: 4.6996\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6788\n",
      "Epoch 00084: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6788 - val_loss: 4.6940\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00085: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6724 - val_loss: 4.6790\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6833\n",
      "Epoch 00086: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6833 - val_loss: 4.6928\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6847\n",
      "Epoch 00087: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6847 - val_loss: 4.6945\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00088: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6820 - val_loss: 4.6945\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6700\n",
      "Epoch 00089: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 9.155273517080786e-08.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6700 - val_loss: 4.6907\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00090: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6842 - val_loss: 4.7004\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6652\n",
      "Epoch 00091: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6652 - val_loss: 4.7025\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6712\n",
      "Epoch 00092: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6712 - val_loss: 4.6987\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00093: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6820 - val_loss: 4.7064\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6728\n",
      "Epoch 00094: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.577636758540393e-08.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6728 - val_loss: 4.7111\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6687\n",
      "Epoch 00095: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6687 - val_loss: 4.7000\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6792\n",
      "Epoch 00096: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6792 - val_loss: 4.6979\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6780\n",
      "Epoch 00097: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6780 - val_loss: 4.7054\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6729\n",
      "Epoch 00098: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6729 - val_loss: 4.6883\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00099: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 2.2888183792701966e-08.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6803 - val_loss: 4.6978\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6637\n",
      "Epoch 00100: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6637 - val_loss: 4.7001\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 00101: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.6794 - val_loss: 4.7054\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6949\n",
      "Epoch 00102: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6949 - val_loss: 4.7012\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6912\n",
      "Epoch 00103: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6912 - val_loss: 4.7084\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6850\n",
      "Epoch 00104: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.1444091896350983e-08.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6850 - val_loss: 4.6805\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00105: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6724 - val_loss: 4.7012\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6713\n",
      "Epoch 00106: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6713 - val_loss: 4.6977\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6648\n",
      "Epoch 00107: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6648 - val_loss: 4.6917\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6773\n",
      "Epoch 00108: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6773 - val_loss: 4.6929\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00109: val_loss did not improve from 4.67747\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6877 - val_loss: 4.6931\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6833\n",
      "Epoch 00110: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6833 - val_loss: 4.7072\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6858\n",
      "Epoch 00111: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6858 - val_loss: 4.6888\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6709\n",
      "Epoch 00112: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6709 - val_loss: 4.6966\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6739\n",
      "Epoch 00113: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6739 - val_loss: 4.7002\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00114: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6842 - val_loss: 4.7096\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6660\n",
      "Epoch 00115: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6660 - val_loss: 4.6862\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6805\n",
      "Epoch 00116: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6805 - val_loss: 4.6896\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6702\n",
      "Epoch 00117: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6702 - val_loss: 4.6944\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6649\n",
      "Epoch 00118: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6649 - val_loss: 4.6965\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6744\n",
      "Epoch 00119: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6744 - val_loss: 4.6953\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6837\n",
      "Epoch 00120: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6837 - val_loss: 4.6944\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6764\n",
      "Epoch 00121: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6764 - val_loss: 4.7022\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6699\n",
      "Epoch 00122: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6699 - val_loss: 4.6888\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6747\n",
      "Epoch 00123: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6747 - val_loss: 4.6947\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6716\n",
      "Epoch 00124: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6716 - val_loss: 4.7215\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6749\n",
      "Epoch 00125: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6749 - val_loss: 4.7075\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6800\n",
      "Epoch 00126: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6800 - val_loss: 4.6967\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6680\n",
      "Epoch 00127: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6680 - val_loss: 4.7140\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6696\n",
      "Epoch 00128: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6696 - val_loss: 4.7146\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6826\n",
      "Epoch 00129: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6826 - val_loss: 4.6983\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6689\n",
      "Epoch 00130: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6689 - val_loss: 4.7046\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6753\n",
      "Epoch 00131: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6753 - val_loss: 4.6893\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6750\n",
      "Epoch 00132: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6750 - val_loss: 4.6914\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6655\n",
      "Epoch 00133: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6655 - val_loss: 4.6987\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6730\n",
      "Epoch 00134: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6730 - val_loss: 4.6919\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6727\n",
      "Epoch 00135: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6727 - val_loss: 4.6897\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6718\n",
      "Epoch 00136: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6718 - val_loss: 4.7062\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6725\n",
      "Epoch 00137: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6725 - val_loss: 4.6921\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6770\n",
      "Epoch 00138: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6770 - val_loss: 4.7068\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6761\n",
      "Epoch 00139: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6761 - val_loss: 4.7044\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6856\n",
      "Epoch 00140: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6856 - val_loss: 4.7133\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6991\n",
      "Epoch 00141: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6991 - val_loss: 4.6986\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6867\n",
      "Epoch 00142: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6867 - val_loss: 4.6909\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6938\n",
      "Epoch 00143: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6938 - val_loss: 4.7043\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6744\n",
      "Epoch 00144: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6744 - val_loss: 4.6969\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00145: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6786 - val_loss: 4.7154\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6978\n",
      "Epoch 00146: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6978 - val_loss: 4.6906\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6789\n",
      "Epoch 00147: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6789 - val_loss: 4.7197\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6707\n",
      "Epoch 00148: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6707 - val_loss: 4.6863\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6714\n",
      "Epoch 00149: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6714 - val_loss: 4.7074\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00150: val_loss did not improve from 4.67747\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6769 - val_loss: 4.6960\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 1 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6956\n",
      "Epoch 00001: val_loss improved from inf to 15027191.00000, saving model to fold-1.h5\n",
      "32/32 [==============================] - 23s 706ms/step - loss: 4.6956 - val_loss: 15027191.0000\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00002: val_loss improved from 15027191.00000 to 1195.45801, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6797 - val_loss: 1195.4580\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6954\n",
      "Epoch 00003: val_loss improved from 1195.45801 to 191.28046, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 4.6954 - val_loss: 191.2805\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6826\n",
      "Epoch 00004: val_loss improved from 191.28046 to 5.75883, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 617ms/step - loss: 4.6826 - val_loss: 5.7588\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6874\n",
      "Epoch 00005: val_loss improved from 5.75883 to 4.99080, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 624ms/step - loss: 4.6874 - val_loss: 4.9908\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00006: val_loss improved from 4.99080 to 4.87678, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 626ms/step - loss: 4.6810 - val_loss: 4.8768\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6852\n",
      "Epoch 00007: val_loss did not improve from 4.87678\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6852 - val_loss: 4.9279\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6827\n",
      "Epoch 00008: val_loss improved from 4.87678 to 4.69954, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 615ms/step - loss: 4.6827 - val_loss: 4.6995\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6905\n",
      "Epoch 00009: val_loss did not improve from 4.69954\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6905 - val_loss: 8.0773\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6833\n",
      "Epoch 00010: val_loss did not improve from 4.69954\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6833 - val_loss: 5.7111\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6838\n",
      "Epoch 00011: val_loss improved from 4.69954 to 4.68851, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 4.6838 - val_loss: 4.6885\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6944\n",
      "Epoch 00012: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6944 - val_loss: 5.0273\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6777\n",
      "Epoch 00013: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6777 - val_loss: 5.1543\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6771\n",
      "Epoch 00014: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6771 - val_loss: 5.2443\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6918\n",
      "Epoch 00015: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6918 - val_loss: 6359.2139\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00016: val_loss did not improve from 4.68851\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6808 - val_loss: 127.8325\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7002\n",
      "Epoch 00017: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.7002 - val_loss: 5.2461\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6890\n",
      "Epoch 00018: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6890 - val_loss: 4.8037\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6865\n",
      "Epoch 00019: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6865 - val_loss: 4.8749\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6837\n",
      "Epoch 00020: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6837 - val_loss: 4.6999\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6855\n",
      "Epoch 00021: val_loss did not improve from 4.68851\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6855 - val_loss: 4.7203\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6918\n",
      "Epoch 00022: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6918 - val_loss: 4.7193\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6800\n",
      "Epoch 00023: val_loss did not improve from 4.68851\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6800 - val_loss: 4.7113\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6854\n",
      "Epoch 00024: val_loss improved from 4.68851 to 4.67482, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6854 - val_loss: 4.6748\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6848\n",
      "Epoch 00025: val_loss did not improve from 4.67482\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6848 - val_loss: 4.7086\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6847\n",
      "Epoch 00026: val_loss did not improve from 4.67482\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6847 - val_loss: 4.6820\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6743\n",
      "Epoch 00027: val_loss did not improve from 4.67482\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6743 - val_loss: 4.6937\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6991\n",
      "Epoch 00028: val_loss did not improve from 4.67482\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6991 - val_loss: 4.7022\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6727\n",
      "Epoch 00029: val_loss did not improve from 4.67482\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6727 - val_loss: 4.6796\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6765\n",
      "Epoch 00030: val_loss improved from 4.67482 to 4.67045, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 618ms/step - loss: 4.6765 - val_loss: 4.6705\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6858\n",
      "Epoch 00031: val_loss improved from 4.67045 to 4.67039, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6858 - val_loss: 4.6704\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6772\n",
      "Epoch 00032: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6772 - val_loss: 4.6950\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6876\n",
      "Epoch 00033: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6876 - val_loss: 4.6958\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6737\n",
      "Epoch 00034: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6737 - val_loss: 4.6979\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6710\n",
      "Epoch 00035: val_loss did not improve from 4.67039\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6710 - val_loss: 4.6929\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6659\n",
      "Epoch 00036: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6659 - val_loss: 4.6791\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00037: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6797 - val_loss: 4.6733\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6772\n",
      "Epoch 00038: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6772 - val_loss: 4.6898\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6902\n",
      "Epoch 00039: val_loss did not improve from 4.67039\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6902 - val_loss: 4.6758\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6735\n",
      "Epoch 00040: val_loss improved from 4.67039 to 4.65928, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6735 - val_loss: 4.6593\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6950\n",
      "Epoch 00041: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6950 - val_loss: 4.6855\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6701\n",
      "Epoch 00042: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6701 - val_loss: 4.6831\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6837\n",
      "Epoch 00043: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6837 - val_loss: 4.6594\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6806\n",
      "Epoch 00044: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6806 - val_loss: 4.6840\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6706\n",
      "Epoch 00045: val_loss did not improve from 4.65928\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6706 - val_loss: 4.7220\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6750\n",
      "Epoch 00046: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6750 - val_loss: 4.6947\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6755\n",
      "Epoch 00047: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6755 - val_loss: 4.6654\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6807\n",
      "Epoch 00048: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6807 - val_loss: 4.6910\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6896\n",
      "Epoch 00049: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6896 - val_loss: 4.6769\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00050: val_loss did not improve from 4.65928\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6866 - val_loss: 4.6709\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6763\n",
      "Epoch 00051: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6763 - val_loss: 4.6757\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6868\n",
      "Epoch 00052: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6868 - val_loss: 4.6756\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6897\n",
      "Epoch 00053: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6897 - val_loss: 4.6911\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00054: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6822 - val_loss: 4.6810\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6823\n",
      "Epoch 00055: val_loss did not improve from 4.65928\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6823 - val_loss: 4.6793\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00056: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6803 - val_loss: 4.6643\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6748\n",
      "Epoch 00057: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6748 - val_loss: 4.6836\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6882\n",
      "Epoch 00058: val_loss did not improve from 4.65928\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6882 - val_loss: 4.6593\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6963\n",
      "Epoch 00059: val_loss improved from 4.65928 to 4.65783, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 619ms/step - loss: 4.6963 - val_loss: 4.6578\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6893\n",
      "Epoch 00060: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6893 - val_loss: 4.6734\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6951\n",
      "Epoch 00061: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6951 - val_loss: 4.6865\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6958\n",
      "Epoch 00062: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6958 - val_loss: 4.6629\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6729\n",
      "Epoch 00063: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6729 - val_loss: 4.6729\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6795\n",
      "Epoch 00064: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6795 - val_loss: 4.7012\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6788\n",
      "Epoch 00065: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6788 - val_loss: 4.6796\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00066: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6886 - val_loss: 4.6921\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6935\n",
      "Epoch 00067: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6935 - val_loss: 4.6723\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6880\n",
      "Epoch 00068: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6880 - val_loss: 4.6835\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6888\n",
      "Epoch 00069: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6888 - val_loss: 4.6747\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6744\n",
      "Epoch 00070: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6744 - val_loss: 4.6718\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6817\n",
      "Epoch 00071: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6817 - val_loss: 4.6698\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6910\n",
      "Epoch 00072: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6910 - val_loss: 4.6584\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6740\n",
      "Epoch 00073: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6740 - val_loss: 4.6899\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6824\n",
      "Epoch 00074: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6824 - val_loss: 4.6669\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6881\n",
      "Epoch 00075: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6881 - val_loss: 4.6808\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6960\n",
      "Epoch 00076: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6960 - val_loss: 4.7064\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6777\n",
      "Epoch 00077: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6777 - val_loss: 4.6634\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00078: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6809 - val_loss: 4.6618\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6832\n",
      "Epoch 00079: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6832 - val_loss: 4.6733\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6828\n",
      "Epoch 00080: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6828 - val_loss: 4.6996\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6630\n",
      "Epoch 00081: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6630 - val_loss: 4.6842\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6751\n",
      "Epoch 00082: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6751 - val_loss: 4.6733\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6921\n",
      "Epoch 00083: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.6921 - val_loss: 4.6735\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6859\n",
      "Epoch 00084: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6859 - val_loss: 4.6889\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6801\n",
      "Epoch 00085: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6801 - val_loss: 4.6830\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6778\n",
      "Epoch 00086: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6778 - val_loss: 4.6851\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6784\n",
      "Epoch 00087: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6784 - val_loss: 4.6845\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6850\n",
      "Epoch 00088: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6850 - val_loss: 4.6770\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6773\n",
      "Epoch 00089: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6773 - val_loss: 4.6947\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6746\n",
      "Epoch 00090: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6746 - val_loss: 4.6770\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6821\n",
      "Epoch 00091: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6821 - val_loss: 4.7214\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6824\n",
      "Epoch 00092: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6824 - val_loss: 4.6633\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 00093: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6794 - val_loss: 4.6691\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6899\n",
      "Epoch 00094: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6899 - val_loss: 4.7134\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6748\n",
      "Epoch 00095: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6748 - val_loss: 4.6843\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6735\n",
      "Epoch 00096: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6735 - val_loss: 4.6833\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6729\n",
      "Epoch 00097: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6729 - val_loss: 4.6675\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6837\n",
      "Epoch 00098: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6837 - val_loss: 4.6763\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6782\n",
      "Epoch 00099: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 9.155273517080786e-08.\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6782 - val_loss: 4.6796\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6892\n",
      "Epoch 00100: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6892 - val_loss: 4.6706\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6841\n",
      "Epoch 00101: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6841 - val_loss: 4.6988\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6696\n",
      "Epoch 00102: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6696 - val_loss: 4.6810\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6890\n",
      "Epoch 00103: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6890 - val_loss: 4.6870\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6654\n",
      "Epoch 00104: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 4.577636758540393e-08.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6654 - val_loss: 4.6751\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6806\n",
      "Epoch 00105: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6806 - val_loss: 4.6811\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00106: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6866 - val_loss: 4.6742\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6728\n",
      "Epoch 00107: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6728 - val_loss: 4.6848\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00108: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6803 - val_loss: 4.6854\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6947\n",
      "Epoch 00109: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.2888183792701966e-08.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6947 - val_loss: 4.6586\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6710\n",
      "Epoch 00110: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6710 - val_loss: 4.6743\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6873\n",
      "Epoch 00111: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6873 - val_loss: 4.6657\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6788\n",
      "Epoch 00112: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6788 - val_loss: 4.6796\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6884\n",
      "Epoch 00113: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6884 - val_loss: 4.6859\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6814\n",
      "Epoch 00114: val_loss did not improve from 4.65783\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.1444091896350983e-08.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6814 - val_loss: 4.6732\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6863\n",
      "Epoch 00115: val_loss did not improve from 4.65783\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6863 - val_loss: 4.6704\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6698\n",
      "Epoch 00116: val_loss improved from 4.65783 to 4.65376, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 627ms/step - loss: 4.6698 - val_loss: 4.6538\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6826\n",
      "Epoch 00117: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6826 - val_loss: 4.6760\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7053\n",
      "Epoch 00118: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.7053 - val_loss: 4.6820\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6685\n",
      "Epoch 00119: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6685 - val_loss: 4.6724\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6947\n",
      "Epoch 00120: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6947 - val_loss: 4.6780\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6882\n",
      "Epoch 00121: val_loss did not improve from 4.65376\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6882 - val_loss: 4.6650\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6954\n",
      "Epoch 00122: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6954 - val_loss: 4.6709\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6648\n",
      "Epoch 00123: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6648 - val_loss: 4.7084\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6652\n",
      "Epoch 00124: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6652 - val_loss: 4.6916\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6844\n",
      "Epoch 00125: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6844 - val_loss: 4.6739\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7023\n",
      "Epoch 00126: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.7023 - val_loss: 4.6555\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6768\n",
      "Epoch 00127: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6768 - val_loss: 4.6755\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00128: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6769 - val_loss: 4.6846\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6798\n",
      "Epoch 00129: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.6798 - val_loss: 4.7036\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00130: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6842 - val_loss: 4.6719\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6872\n",
      "Epoch 00131: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6872 - val_loss: 4.6791\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6787\n",
      "Epoch 00132: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6787 - val_loss: 4.6837\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6700\n",
      "Epoch 00133: val_loss did not improve from 4.65376\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6700 - val_loss: 4.6655\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6858\n",
      "Epoch 00134: val_loss improved from 4.65376 to 4.64564, saving model to fold-1.h5\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 4.6858 - val_loss: 4.6456\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6741\n",
      "Epoch 00135: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6741 - val_loss: 4.6704\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6840\n",
      "Epoch 00136: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6840 - val_loss: 4.6784\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6859\n",
      "Epoch 00137: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6859 - val_loss: 4.6813\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6859\n",
      "Epoch 00138: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6859 - val_loss: 4.6894\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6867\n",
      "Epoch 00139: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6867 - val_loss: 4.6841\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6833\n",
      "Epoch 00140: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6833 - val_loss: 4.6977\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6776\n",
      "Epoch 00141: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6776 - val_loss: 4.6757\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6821\n",
      "Epoch 00142: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6821 - val_loss: 4.6602\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6659\n",
      "Epoch 00143: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6659 - val_loss: 4.6693\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6793\n",
      "Epoch 00144: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6793 - val_loss: 4.6954\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6845\n",
      "Epoch 00145: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6845 - val_loss: 4.6664\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6876\n",
      "Epoch 00146: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6876 - val_loss: 4.6734\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6759\n",
      "Epoch 00147: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6759 - val_loss: 4.6756\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6885\n",
      "Epoch 00148: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6885 - val_loss: 4.6952\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6708\n",
      "Epoch 00149: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.6708 - val_loss: 4.6756\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6753\n",
      "Epoch 00150: val_loss did not improve from 4.64564\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6753 - val_loss: 4.6708\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 2 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7026\n",
      "Epoch 00001: val_loss improved from inf to 831579.62500, saving model to fold-2.h5\n",
      "32/32 [==============================] - 24s 755ms/step - loss: 4.7026 - val_loss: 831579.6250\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00002: val_loss improved from 831579.62500 to 5739.41650, saving model to fold-2.h5\n",
      "32/32 [==============================] - 19s 606ms/step - loss: 4.6818 - val_loss: 5739.4165\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6806\n",
      "Epoch 00003: val_loss improved from 5739.41650 to 1474.38623, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 619ms/step - loss: 4.6806 - val_loss: 1474.3862\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7034\n",
      "Epoch 00004: val_loss improved from 1474.38623 to 7.22227, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 4.7034 - val_loss: 7.2223\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7030\n",
      "Epoch 00005: val_loss did not improve from 7.22227\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.7030 - val_loss: 7.5845\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6917\n",
      "Epoch 00006: val_loss improved from 7.22227 to 4.65536, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 634ms/step - loss: 4.6917 - val_loss: 4.6554\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6897\n",
      "Epoch 00007: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6897 - val_loss: 8.2227\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7016\n",
      "Epoch 00008: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.7016 - val_loss: 6.9562\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6849\n",
      "Epoch 00009: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6849 - val_loss: 26.6034\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00010: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6877 - val_loss: 5.0700\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6889\n",
      "Epoch 00011: val_loss did not improve from 4.65536\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6889 - val_loss: 679.9127\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6812\n",
      "Epoch 00012: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6812 - val_loss: 5.0392\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7005\n",
      "Epoch 00013: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.7005 - val_loss: 4.9511\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6992\n",
      "Epoch 00014: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6992 - val_loss: 16.8184\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6814\n",
      "Epoch 00015: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6814 - val_loss: 6.9933\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6836\n",
      "Epoch 00016: val_loss did not improve from 4.65536\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6836 - val_loss: 9.1193\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6923\n",
      "Epoch 00017: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6923 - val_loss: 5.8436\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6853\n",
      "Epoch 00018: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6853 - val_loss: 4.6850\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6908\n",
      "Epoch 00019: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6908 - val_loss: 4.6781\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6816\n",
      "Epoch 00020: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6816 - val_loss: 4.6997\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6907\n",
      "Epoch 00021: val_loss did not improve from 4.65536\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6907 - val_loss: 4.9489\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6700\n",
      "Epoch 00022: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6700 - val_loss: 4.8797\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6801\n",
      "Epoch 00023: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6801 - val_loss: 4.7053\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6824\n",
      "Epoch 00024: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6824 - val_loss: 4.6674\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7021\n",
      "Epoch 00025: val_loss did not improve from 4.65536\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.7021 - val_loss: 4.6715\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00026: val_loss did not improve from 4.65536\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6866 - val_loss: 4.6721\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00027: val_loss improved from 4.65536 to 4.65478, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 4.6842 - val_loss: 4.6548\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6726\n",
      "Epoch 00028: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6726 - val_loss: 4.6755\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6967\n",
      "Epoch 00029: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6967 - val_loss: 4.6617\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6917\n",
      "Epoch 00030: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6917 - val_loss: 4.6705\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6789\n",
      "Epoch 00031: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6789 - val_loss: 4.6598\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6860\n",
      "Epoch 00032: val_loss did not improve from 4.65478\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6860 - val_loss: 4.6855\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6932\n",
      "Epoch 00033: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6932 - val_loss: 4.6720\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6725\n",
      "Epoch 00034: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6725 - val_loss: 4.6634\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00035: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6886 - val_loss: 4.6836\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6760\n",
      "Epoch 00036: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6760 - val_loss: 4.6658\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6802\n",
      "Epoch 00037: val_loss did not improve from 4.65478\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6802 - val_loss: 4.6732\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6851\n",
      "Epoch 00038: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6851 - val_loss: 4.6643\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00039: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6886 - val_loss: 4.6560\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6755\n",
      "Epoch 00040: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6755 - val_loss: 4.6877\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00041: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6818 - val_loss: 4.6616\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6831\n",
      "Epoch 00042: val_loss did not improve from 4.65478\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6831 - val_loss: 4.6710\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6891\n",
      "Epoch 00043: val_loss did not improve from 4.65478\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6891 - val_loss: 4.6653\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6832\n",
      "Epoch 00044: val_loss improved from 4.65478 to 4.65170, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 4.6832 - val_loss: 4.6517\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6767\n",
      "Epoch 00045: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6767 - val_loss: 4.6669\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6889\n",
      "Epoch 00046: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6889 - val_loss: 4.6781\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00047: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6842 - val_loss: 4.6603\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6823\n",
      "Epoch 00048: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6823 - val_loss: 4.6604\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6999\n",
      "Epoch 00049: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6999 - val_loss: 4.6589\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6771\n",
      "Epoch 00050: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6771 - val_loss: 4.6590\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6828\n",
      "Epoch 00051: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6828 - val_loss: 4.6575\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00052: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6842 - val_loss: 4.6779\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6753\n",
      "Epoch 00053: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6753 - val_loss: 4.6650\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6911\n",
      "Epoch 00054: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6911 - val_loss: 4.6760\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6829\n",
      "Epoch 00055: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6829 - val_loss: 4.6810\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6859\n",
      "Epoch 00056: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6859 - val_loss: 4.6715\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6892\n",
      "Epoch 00057: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6892 - val_loss: 4.6862\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6824\n",
      "Epoch 00058: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6824 - val_loss: 4.6591\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6861\n",
      "Epoch 00059: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6861 - val_loss: 4.6639\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6771\n",
      "Epoch 00060: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6771 - val_loss: 4.6553\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6887\n",
      "Epoch 00061: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6887 - val_loss: 4.6576\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7114\n",
      "Epoch 00062: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.7114 - val_loss: 4.6804\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 00063: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6794 - val_loss: 4.6568\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6878\n",
      "Epoch 00064: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6878 - val_loss: 4.6681\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6842\n",
      "Epoch 00065: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6842 - val_loss: 4.6711\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6819\n",
      "Epoch 00066: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6819 - val_loss: 4.6591\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6894\n",
      "Epoch 00067: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6894 - val_loss: 4.6615\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00068: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6820 - val_loss: 4.6681\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6793\n",
      "Epoch 00069: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6793 - val_loss: 4.6708\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6933\n",
      "Epoch 00070: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6933 - val_loss: 4.6627\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6857\n",
      "Epoch 00071: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6857 - val_loss: 4.6570\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00072: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6818 - val_loss: 4.6677\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6829\n",
      "Epoch 00073: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6829 - val_loss: 4.6750\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6737\n",
      "Epoch 00074: val_loss did not improve from 4.65170\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6737 - val_loss: 4.6570\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6825\n",
      "Epoch 00075: val_loss did not improve from 4.65170\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6825 - val_loss: 4.6739\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6783\n",
      "Epoch 00076: val_loss improved from 4.65170 to 4.64795, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 4.6783 - val_loss: 4.6480\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6838\n",
      "Epoch 00077: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6838 - val_loss: 4.6742\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00078: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6822 - val_loss: 4.6644\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6843\n",
      "Epoch 00079: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6843 - val_loss: 4.6638\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6850\n",
      "Epoch 00080: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6850 - val_loss: 4.6618\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6781\n",
      "Epoch 00081: val_loss did not improve from 4.64795\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6781 - val_loss: 4.6702\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6899\n",
      "Epoch 00082: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6899 - val_loss: 4.6685\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6757\n",
      "Epoch 00083: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6757 - val_loss: 4.6722\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6731\n",
      "Epoch 00084: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6731 - val_loss: 4.6765\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6870\n",
      "Epoch 00085: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6870 - val_loss: 4.6555\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6882\n",
      "Epoch 00086: val_loss did not improve from 4.64795\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.155273517080786e-08.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6882 - val_loss: 4.6871\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00087: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6797 - val_loss: 4.6791\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6872\n",
      "Epoch 00088: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6872 - val_loss: 4.6799\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6800\n",
      "Epoch 00089: val_loss did not improve from 4.64795\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6800 - val_loss: 4.6692\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6812\n",
      "Epoch 00090: val_loss improved from 4.64795 to 4.64666, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 614ms/step - loss: 4.6812 - val_loss: 4.6467\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6888\n",
      "Epoch 00091: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6888 - val_loss: 4.6736\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6848\n",
      "Epoch 00092: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6848 - val_loss: 4.6696\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6904\n",
      "Epoch 00093: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6904 - val_loss: 4.6671\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6905\n",
      "Epoch 00094: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6905 - val_loss: 4.6552\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6892\n",
      "Epoch 00095: val_loss did not improve from 4.64666\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.577636758540393e-08.\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6892 - val_loss: 4.6594\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6814\n",
      "Epoch 00096: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6814 - val_loss: 4.6593\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6911\n",
      "Epoch 00097: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6911 - val_loss: 4.6698\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6929\n",
      "Epoch 00098: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6929 - val_loss: 4.6720\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6986\n",
      "Epoch 00099: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6986 - val_loss: 4.6652\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6709\n",
      "Epoch 00100: val_loss did not improve from 4.64666\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 2.2888183792701966e-08.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6709 - val_loss: 4.6759\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6855\n",
      "Epoch 00101: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6855 - val_loss: 4.6807\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7011\n",
      "Epoch 00102: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.7011 - val_loss: 4.6687\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6931\n",
      "Epoch 00103: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6931 - val_loss: 4.6611\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6956\n",
      "Epoch 00104: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6956 - val_loss: 4.6830\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6981\n",
      "Epoch 00105: val_loss did not improve from 4.64666\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.1444091896350983e-08.\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6981 - val_loss: 4.6676\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6896\n",
      "Epoch 00106: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6896 - val_loss: 4.6849\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6840\n",
      "Epoch 00107: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6840 - val_loss: 4.6559\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6854\n",
      "Epoch 00108: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6854 - val_loss: 4.6791\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6896\n",
      "Epoch 00109: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6896 - val_loss: 4.6551\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6766\n",
      "Epoch 00110: val_loss did not improve from 4.64666\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6766 - val_loss: 4.6663\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6908\n",
      "Epoch 00111: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6908 - val_loss: 4.6711\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6819\n",
      "Epoch 00112: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6819 - val_loss: 4.6744\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6833\n",
      "Epoch 00113: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6833 - val_loss: 4.6817\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6956\n",
      "Epoch 00114: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6956 - val_loss: 4.6746\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6923\n",
      "Epoch 00115: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6923 - val_loss: 4.6500\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6789\n",
      "Epoch 00116: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6789 - val_loss: 4.6721\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00117: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6866 - val_loss: 4.6856\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6857\n",
      "Epoch 00118: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6857 - val_loss: 4.6761\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6763\n",
      "Epoch 00119: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6763 - val_loss: 4.6565\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6856\n",
      "Epoch 00120: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6856 - val_loss: 4.6652\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6800\n",
      "Epoch 00121: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6800 - val_loss: 4.6524\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6821\n",
      "Epoch 00122: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6821 - val_loss: 4.6569\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00123: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6866 - val_loss: 4.6727\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6782\n",
      "Epoch 00124: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6782 - val_loss: 4.6611\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6969\n",
      "Epoch 00125: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6969 - val_loss: 4.6652\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00126: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6820 - val_loss: 4.6833\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6921\n",
      "Epoch 00127: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6921 - val_loss: 4.6583\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6900\n",
      "Epoch 00128: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6900 - val_loss: 4.6750\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6728\n",
      "Epoch 00129: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6728 - val_loss: 4.6566\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6870\n",
      "Epoch 00130: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6870 - val_loss: 4.6781\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6913\n",
      "Epoch 00131: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6913 - val_loss: 4.6847\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6823\n",
      "Epoch 00132: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6823 - val_loss: 4.6692\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6872\n",
      "Epoch 00133: val_loss did not improve from 4.64666\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6872 - val_loss: 4.6672\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6977\n",
      "Epoch 00134: val_loss improved from 4.64666 to 4.64618, saving model to fold-2.h5\n",
      "32/32 [==============================] - 20s 614ms/step - loss: 4.6977 - val_loss: 4.6462\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6773\n",
      "Epoch 00135: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6773 - val_loss: 4.6642\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6783\n",
      "Epoch 00136: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6783 - val_loss: 4.6544\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00137: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6797 - val_loss: 4.6575\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6785\n",
      "Epoch 00138: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6785 - val_loss: 4.6762\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6882\n",
      "Epoch 00139: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6882 - val_loss: 4.6692\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6811\n",
      "Epoch 00140: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6811 - val_loss: 4.6685\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6825\n",
      "Epoch 00141: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6825 - val_loss: 4.6754\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00142: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6886 - val_loss: 4.6754\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6984\n",
      "Epoch 00143: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6984 - val_loss: 4.6788\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6868\n",
      "Epoch 00144: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6868 - val_loss: 4.6479\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6748\n",
      "Epoch 00145: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6748 - val_loss: 4.6562\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6863\n",
      "Epoch 00146: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6863 - val_loss: 4.6707\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6838\n",
      "Epoch 00147: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6838 - val_loss: 4.6565\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6846\n",
      "Epoch 00148: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6846 - val_loss: 4.6629\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00149: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6822 - val_loss: 4.6765\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6857\n",
      "Epoch 00150: val_loss did not improve from 4.64618\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6857 - val_loss: 4.6701\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 3 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7056\n",
      "Epoch 00001: val_loss improved from inf to 15194774.00000, saving model to fold-3.h5\n",
      "32/32 [==============================] - 24s 761ms/step - loss: 4.7056 - val_loss: 15194774.0000\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6794\n",
      "Epoch 00002: val_loss improved from 15194774.00000 to 329032.46875, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 4.6794 - val_loss: 329032.4688\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6779\n",
      "Epoch 00003: val_loss improved from 329032.46875 to 600.17938, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 618ms/step - loss: 4.6779 - val_loss: 600.1794\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6924\n",
      "Epoch 00004: val_loss improved from 600.17938 to 305.82324, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 614ms/step - loss: 4.6924 - val_loss: 305.8232\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6887\n",
      "Epoch 00005: val_loss did not improve from 305.82324\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6887 - val_loss: 855.2816\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6751\n",
      "Epoch 00006: val_loss improved from 305.82324 to 30.41492, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 632ms/step - loss: 4.6751 - val_loss: 30.4149\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6762\n",
      "Epoch 00007: val_loss improved from 30.41492 to 23.27472, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 4.6762 - val_loss: 23.2747\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6908\n",
      "Epoch 00008: val_loss did not improve from 23.27472\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6908 - val_loss: 324.5724\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6940\n",
      "Epoch 00009: val_loss did not improve from 23.27472\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6940 - val_loss: 93.4430\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6795\n",
      "Epoch 00010: val_loss improved from 23.27472 to 4.67941, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 622ms/step - loss: 4.6795 - val_loss: 4.6794\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00011: val_loss did not improve from 4.67941\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6866 - val_loss: 4.7059\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6962\n",
      "Epoch 00012: val_loss did not improve from 4.67941\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6962 - val_loss: 4.6943\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6853\n",
      "Epoch 00013: val_loss did not improve from 4.67941\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6853 - val_loss: 20.0793\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6845\n",
      "Epoch 00014: val_loss did not improve from 4.67941\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6845 - val_loss: 4.6887\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6684\n",
      "Epoch 00015: val_loss improved from 4.67941 to 4.66823, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 4.6684 - val_loss: 4.6682\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6914\n",
      "Epoch 00016: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6914 - val_loss: 4.8925\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6938\n",
      "Epoch 00017: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.6938 - val_loss: 4.7005\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6717\n",
      "Epoch 00018: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6717 - val_loss: 4.6815\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6844\n",
      "Epoch 00019: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6844 - val_loss: 4.8160\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6831\n",
      "Epoch 00020: val_loss did not improve from 4.66823\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6831 - val_loss: 5.3121\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00021: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6786 - val_loss: 4.8315\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6862\n",
      "Epoch 00022: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6862 - val_loss: 4.9954\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6932\n",
      "Epoch 00023: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6932 - val_loss: 4.6716\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6997\n",
      "Epoch 00024: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6997 - val_loss: 4.6896\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6779\n",
      "Epoch 00025: val_loss did not improve from 4.66823\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6779 - val_loss: 4.6756\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6806\n",
      "Epoch 00026: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6806 - val_loss: 4.6802\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6918\n",
      "Epoch 00027: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6918 - val_loss: 4.6717\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00028: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6724 - val_loss: 4.6942\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6802\n",
      "Epoch 00029: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6802 - val_loss: 4.6731\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6839\n",
      "Epoch 00030: val_loss did not improve from 4.66823\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6839 - val_loss: 4.6898\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6718\n",
      "Epoch 00031: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6718 - val_loss: 4.6882\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6763\n",
      "Epoch 00032: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6763 - val_loss: 4.7024\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6870\n",
      "Epoch 00033: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6870 - val_loss: 4.6825\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6787\n",
      "Epoch 00034: val_loss did not improve from 4.66823\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6787 - val_loss: 4.6785\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00035: val_loss improved from 4.66823 to 4.66798, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 617ms/step - loss: 4.6769 - val_loss: 4.6680\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6982\n",
      "Epoch 00036: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.6982 - val_loss: 4.6919\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6878\n",
      "Epoch 00037: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6878 - val_loss: 4.6961\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6681\n",
      "Epoch 00038: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6681 - val_loss: 4.6849\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6811\n",
      "Epoch 00039: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6811 - val_loss: 4.6996\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6882\n",
      "Epoch 00040: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6882 - val_loss: 4.6848\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00041: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6877 - val_loss: 4.6925\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6844\n",
      "Epoch 00042: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6844 - val_loss: 4.6900\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6959\n",
      "Epoch 00043: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6959 - val_loss: 4.7158\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6690\n",
      "Epoch 00044: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.6690 - val_loss: 4.7093\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6845\n",
      "Epoch 00045: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6845 - val_loss: 4.6823\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6959\n",
      "Epoch 00046: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6959 - val_loss: 4.6733\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6723\n",
      "Epoch 00047: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6723 - val_loss: 4.6780\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6828\n",
      "Epoch 00048: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6828 - val_loss: 4.6866\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6884\n",
      "Epoch 00049: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6884 - val_loss: 4.7046\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00050: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6818 - val_loss: 4.6892\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7029\n",
      "Epoch 00051: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.7029 - val_loss: 4.7060\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6723\n",
      "Epoch 00052: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6723 - val_loss: 4.6868\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6748\n",
      "Epoch 00053: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6748 - val_loss: 4.6853\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00054: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6809 - val_loss: 4.7062\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6864\n",
      "Epoch 00055: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6864 - val_loss: 4.6955\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6729\n",
      "Epoch 00056: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6729 - val_loss: 4.6796\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6706\n",
      "Epoch 00057: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6706 - val_loss: 4.6857\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6745\n",
      "Epoch 00058: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6745 - val_loss: 4.6736\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6868\n",
      "Epoch 00059: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6868 - val_loss: 4.6876\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6784\n",
      "Epoch 00060: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6784 - val_loss: 4.6955\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6856\n",
      "Epoch 00061: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6856 - val_loss: 4.6964\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6754\n",
      "Epoch 00062: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6754 - val_loss: 4.6755\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6837\n",
      "Epoch 00063: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6837 - val_loss: 4.6925\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6779\n",
      "Epoch 00064: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6779 - val_loss: 4.6885\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6755\n",
      "Epoch 00065: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6755 - val_loss: 4.6842\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6850\n",
      "Epoch 00066: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6850 - val_loss: 4.6902\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6796\n",
      "Epoch 00067: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6796 - val_loss: 4.7001\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00068: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6808 - val_loss: 4.6939\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6800\n",
      "Epoch 00069: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6800 - val_loss: 4.6977\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6792\n",
      "Epoch 00070: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6792 - val_loss: 4.6879\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6765\n",
      "Epoch 00071: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6765 - val_loss: 4.6936\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6831\n",
      "Epoch 00072: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6831 - val_loss: 4.6966\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6813\n",
      "Epoch 00073: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6813 - val_loss: 4.6734\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6768\n",
      "Epoch 00074: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6768 - val_loss: 4.6742\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00075: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6809 - val_loss: 4.6891\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6804\n",
      "Epoch 00076: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6804 - val_loss: 4.6795\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6718\n",
      "Epoch 00077: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6718 - val_loss: 4.6876\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6888\n",
      "Epoch 00078: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6888 - val_loss: 4.6941\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6828\n",
      "Epoch 00079: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6828 - val_loss: 4.6826\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6907\n",
      "Epoch 00080: val_loss did not improve from 4.66798\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6907 - val_loss: 4.6821\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00081: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6822 - val_loss: 4.6843\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6746\n",
      "Epoch 00082: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6746 - val_loss: 4.6760\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6692\n",
      "Epoch 00083: val_loss did not improve from 4.66798\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6692 - val_loss: 4.6895\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6865\n",
      "Epoch 00084: val_loss improved from 4.66798 to 4.66115, saving model to fold-3.h5\n",
      "32/32 [==============================] - 20s 625ms/step - loss: 4.6865 - val_loss: 4.6611\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6795\n",
      "Epoch 00085: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6795 - val_loss: 4.6843\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6902\n",
      "Epoch 00086: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 565ms/step - loss: 4.6902 - val_loss: 4.7021\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6869\n",
      "Epoch 00087: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6869 - val_loss: 4.6843\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6880\n",
      "Epoch 00088: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6880 - val_loss: 4.6847\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6909\n",
      "Epoch 00089: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6909 - val_loss: 4.6900\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6894\n",
      "Epoch 00090: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6894 - val_loss: 4.6948\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6879\n",
      "Epoch 00091: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6879 - val_loss: 4.6852\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6733\n",
      "Epoch 00092: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6733 - val_loss: 4.6948\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6749\n",
      "Epoch 00093: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6749 - val_loss: 4.6768\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00094: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6810 - val_loss: 4.6784\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6705\n",
      "Epoch 00095: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6705 - val_loss: 4.6825\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6785\n",
      "Epoch 00096: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6785 - val_loss: 4.6907\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6945\n",
      "Epoch 00097: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6945 - val_loss: 4.6761\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6624\n",
      "Epoch 00098: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6624 - val_loss: 4.6666\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6881\n",
      "Epoch 00099: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 9.155273517080786e-08.\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6881 - val_loss: 4.6838\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00100: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6810 - val_loss: 4.6796\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6670\n",
      "Epoch 00101: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6670 - val_loss: 4.6763\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6785\n",
      "Epoch 00102: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6785 - val_loss: 4.7035\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6705\n",
      "Epoch 00103: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6705 - val_loss: 4.6974\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6747\n",
      "Epoch 00104: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 4.577636758540393e-08.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6747 - val_loss: 4.7001\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6938\n",
      "Epoch 00105: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6938 - val_loss: 4.7033\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6903\n",
      "Epoch 00106: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.6903 - val_loss: 4.6910\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6752\n",
      "Epoch 00107: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6752 - val_loss: 4.6848\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6812\n",
      "Epoch 00108: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6812 - val_loss: 4.6775\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6760\n",
      "Epoch 00109: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.2888183792701966e-08.\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 4.6760 - val_loss: 4.6835\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6632\n",
      "Epoch 00110: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6632 - val_loss: 4.6994\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6773\n",
      "Epoch 00111: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6773 - val_loss: 4.6937\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6776\n",
      "Epoch 00112: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6776 - val_loss: 4.6850\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6685\n",
      "Epoch 00113: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6685 - val_loss: 4.6812\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6874\n",
      "Epoch 00114: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.1444091896350983e-08.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6874 - val_loss: 4.6896\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6925\n",
      "Epoch 00115: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6925 - val_loss: 4.6827\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6914\n",
      "Epoch 00116: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6914 - val_loss: 4.6989\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6775\n",
      "Epoch 00117: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6775 - val_loss: 4.6989\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6631\n",
      "Epoch 00118: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6631 - val_loss: 4.6758\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6697\n",
      "Epoch 00119: val_loss did not improve from 4.66115\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6697 - val_loss: 4.6641\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6735\n",
      "Epoch 00120: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6735 - val_loss: 4.7037\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6790\n",
      "Epoch 00121: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6790 - val_loss: 4.7006\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6857\n",
      "Epoch 00122: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6857 - val_loss: 4.6780\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00123: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6810 - val_loss: 4.6740\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6854\n",
      "Epoch 00124: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6854 - val_loss: 4.6801\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6750\n",
      "Epoch 00125: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6750 - val_loss: 4.6927\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6717\n",
      "Epoch 00126: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6717 - val_loss: 4.6815\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6819\n",
      "Epoch 00127: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6819 - val_loss: 4.6857\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6729\n",
      "Epoch 00128: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6729 - val_loss: 4.6999\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6780\n",
      "Epoch 00129: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 564ms/step - loss: 4.6780 - val_loss: 4.6796\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00130: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6822 - val_loss: 4.6900\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6736\n",
      "Epoch 00131: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6736 - val_loss: 4.6881\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6838\n",
      "Epoch 00132: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6838 - val_loss: 4.6877\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6870\n",
      "Epoch 00133: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.6870 - val_loss: 4.6761\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6943\n",
      "Epoch 00134: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6943 - val_loss: 4.6702\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6835\n",
      "Epoch 00135: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6835 - val_loss: 4.6748\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6923\n",
      "Epoch 00136: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6923 - val_loss: 4.6993\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6886\n",
      "Epoch 00137: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6886 - val_loss: 4.6982\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6825\n",
      "Epoch 00138: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 556ms/step - loss: 4.6825 - val_loss: 4.6923\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7015\n",
      "Epoch 00139: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.7015 - val_loss: 4.6961\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6661\n",
      "Epoch 00140: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6661 - val_loss: 4.6935\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6906\n",
      "Epoch 00141: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6906 - val_loss: 4.6925\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6775\n",
      "Epoch 00142: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6775 - val_loss: 4.6809\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6901\n",
      "Epoch 00143: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6901 - val_loss: 4.6859\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6912\n",
      "Epoch 00144: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6912 - val_loss: 4.7029\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6846\n",
      "Epoch 00145: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6846 - val_loss: 4.6837\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00146: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6786 - val_loss: 4.7009\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6858\n",
      "Epoch 00147: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6858 - val_loss: 4.6901\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6781\n",
      "Epoch 00148: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6781 - val_loss: 4.7023\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6707\n",
      "Epoch 00149: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 4.6707 - val_loss: 4.6845\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6817\n",
      "Epoch 00150: val_loss did not improve from 4.66115\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6817 - val_loss: 4.7136\n",
      "Training done!\n",
      "#####################\n",
      "####### Fold 4 ######\n",
      "#####################\n",
      "Training...\n",
      "Epoch 1/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7245\n",
      "Epoch 00001: val_loss improved from inf to 80756360.00000, saving model to fold-4.h5\n",
      "32/32 [==============================] - 23s 708ms/step - loss: 4.7245 - val_loss: 80756360.0000\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6899\n",
      "Epoch 00002: val_loss improved from 80756360.00000 to 4.68898, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 610ms/step - loss: 4.6899 - val_loss: 4.6890\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6915\n",
      "Epoch 00003: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6915 - val_loss: 4.8420\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6754\n",
      "Epoch 00004: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6754 - val_loss: 8223.9609\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6813\n",
      "Epoch 00005: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6813 - val_loss: 160.7048\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6823\n",
      "Epoch 00006: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6823 - val_loss: 13.8734\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6986\n",
      "Epoch 00007: val_loss did not improve from 4.68898\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 18s 559ms/step - loss: 4.6986 - val_loss: 10.1602\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6856\n",
      "Epoch 00008: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6856 - val_loss: 4.7244\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00009: val_loss did not improve from 4.68898\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6877 - val_loss: 4.9736\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6868\n",
      "Epoch 00010: val_loss improved from 4.68898 to 4.68888, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 624ms/step - loss: 4.6868 - val_loss: 4.6889\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00011: val_loss improved from 4.68888 to 4.68585, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 632ms/step - loss: 4.6808 - val_loss: 4.6858\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6841\n",
      "Epoch 00012: val_loss improved from 4.68585 to 4.67748, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 616ms/step - loss: 4.6841 - val_loss: 4.6775\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6759\n",
      "Epoch 00013: val_loss did not improve from 4.67748\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6759 - val_loss: 4.7550\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6831\n",
      "Epoch 00014: val_loss did not improve from 4.67748\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6831 - val_loss: 4.6900\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00015: val_loss improved from 4.67748 to 4.65896, saving model to fold-4.h5\n",
      "32/32 [==============================] - 20s 623ms/step - loss: 4.6820 - val_loss: 4.6590\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6735\n",
      "Epoch 00016: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6735 - val_loss: 4.6899\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6943\n",
      "Epoch 00017: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6943 - val_loss: 4.6914\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6910\n",
      "Epoch 00018: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6910 - val_loss: 4.6969\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6707\n",
      "Epoch 00019: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6707 - val_loss: 4.6862\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6830\n",
      "Epoch 00020: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6830 - val_loss: 4.6818\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6977\n",
      "Epoch 00021: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6977 - val_loss: 4.6834\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6902\n",
      "Epoch 00022: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6902 - val_loss: 4.6781\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6922\n",
      "Epoch 00023: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6922 - val_loss: 4.6691\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6832\n",
      "Epoch 00024: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6832 - val_loss: 4.6774\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6827\n",
      "Epoch 00025: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6827 - val_loss: 4.6597\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6903\n",
      "Epoch 00026: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6903 - val_loss: 4.6866\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6934\n",
      "Epoch 00027: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6934 - val_loss: 4.6788\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6888\n",
      "Epoch 00028: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6888 - val_loss: 4.6840\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6792\n",
      "Epoch 00029: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6792 - val_loss: 4.6711\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6926\n",
      "Epoch 00030: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6926 - val_loss: 4.6787\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6838\n",
      "Epoch 00031: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6838 - val_loss: 4.6783\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6722\n",
      "Epoch 00032: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6722 - val_loss: 4.6928\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6798\n",
      "Epoch 00033: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6798 - val_loss: 4.6770\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6881\n",
      "Epoch 00034: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6881 - val_loss: 4.6723\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6753\n",
      "Epoch 00035: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6753 - val_loss: 4.6743\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6804\n",
      "Epoch 00036: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6804 - val_loss: 4.6807\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6933\n",
      "Epoch 00037: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6933 - val_loss: 4.6725\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6745\n",
      "Epoch 00038: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6745 - val_loss: 4.6967\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6846\n",
      "Epoch 00039: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6846 - val_loss: 4.6838\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6895\n",
      "Epoch 00040: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6895 - val_loss: 4.7026\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6795\n",
      "Epoch 00041: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6795 - val_loss: 4.6715\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6878\n",
      "Epoch 00042: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6878 - val_loss: 4.6766\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6907\n",
      "Epoch 00043: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6907 - val_loss: 4.6834\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6822\n",
      "Epoch 00044: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6822 - val_loss: 4.6741\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6843\n",
      "Epoch 00045: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6843 - val_loss: 4.6811\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00046: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6866 - val_loss: 4.6795\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6828\n",
      "Epoch 00047: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6828 - val_loss: 4.6729\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6735\n",
      "Epoch 00048: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6735 - val_loss: 4.6609\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6872\n",
      "Epoch 00049: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6872 - val_loss: 4.6705\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6778\n",
      "Epoch 00050: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6778 - val_loss: 4.6698\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6885\n",
      "Epoch 00051: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6885 - val_loss: 4.6711\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6970\n",
      "Epoch 00052: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6970 - val_loss: 4.6913\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6790\n",
      "Epoch 00053: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6790 - val_loss: 4.6621\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6827\n",
      "Epoch 00054: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6827 - val_loss: 4.6717\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6741\n",
      "Epoch 00055: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6741 - val_loss: 4.6622\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6805\n",
      "Epoch 00056: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6805 - val_loss: 4.7001\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00057: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6786 - val_loss: 4.6854\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00058: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6803 - val_loss: 4.6928\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6836\n",
      "Epoch 00059: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6836 - val_loss: 4.6811\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6936\n",
      "Epoch 00060: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6936 - val_loss: 4.6947\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6746\n",
      "Epoch 00061: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6746 - val_loss: 4.6860\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6929\n",
      "Epoch 00062: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6929 - val_loss: 4.6603\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6925\n",
      "Epoch 00063: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6925 - val_loss: 4.6810\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6874\n",
      "Epoch 00064: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6874 - val_loss: 4.6760\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6754\n",
      "Epoch 00065: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6754 - val_loss: 4.6893\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6745\n",
      "Epoch 00066: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6745 - val_loss: 4.6871\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00067: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6724 - val_loss: 4.6752\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6900\n",
      "Epoch 00068: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6900 - val_loss: 4.6869\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6816\n",
      "Epoch 00069: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6816 - val_loss: 4.6783\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6761\n",
      "Epoch 00070: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6761 - val_loss: 4.6786\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6853\n",
      "Epoch 00071: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6853 - val_loss: 4.6621\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6683\n",
      "Epoch 00072: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6683 - val_loss: 4.6875\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6817\n",
      "Epoch 00073: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 4.6817 - val_loss: 4.6861\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6926\n",
      "Epoch 00074: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6926 - val_loss: 4.6866\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6865\n",
      "Epoch 00075: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 4.6865 - val_loss: 4.6677\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6724\n",
      "Epoch 00076: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6724 - val_loss: 4.6954\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6866\n",
      "Epoch 00077: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6866 - val_loss: 4.6849\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6786\n",
      "Epoch 00078: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 540ms/step - loss: 4.6786 - val_loss: 4.6955\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6807\n",
      "Epoch 00079: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6807 - val_loss: 4.6710\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6885\n",
      "Epoch 00080: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6885 - val_loss: 4.6830\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6734\n",
      "Epoch 00081: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 539ms/step - loss: 4.6734 - val_loss: 4.6791\n",
      "Epoch 82/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7003\n",
      "Epoch 00082: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.7003 - val_loss: 4.6830\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6748\n",
      "Epoch 00083: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 4.6748 - val_loss: 4.6828\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00084: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6769 - val_loss: 4.6609\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6940\n",
      "Epoch 00085: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 9.155273517080786e-08.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6940 - val_loss: 4.6698\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6935\n",
      "Epoch 00086: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6935 - val_loss: 4.6857\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6919\n",
      "Epoch 00087: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6919 - val_loss: 4.6897\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6734\n",
      "Epoch 00088: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6734 - val_loss: 4.6662\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6994\n",
      "Epoch 00089: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6994 - val_loss: 4.6741\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6818\n",
      "Epoch 00090: val_loss did not improve from 4.65896\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 4.577636758540393e-08.\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6818 - val_loss: 4.6708\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6814\n",
      "Epoch 00091: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 18s 555ms/step - loss: 4.6814 - val_loss: 4.6769\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6679\n",
      "Epoch 00092: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6679 - val_loss: 4.6888\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6820\n",
      "Epoch 00093: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6820 - val_loss: 4.7026\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6755\n",
      "Epoch 00094: val_loss did not improve from 4.65896\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6755 - val_loss: 4.6864\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6740\n",
      "Epoch 00095: val_loss improved from 4.65896 to 4.65500, saving model to fold-4.h5\n",
      "32/32 [==============================] - 19s 605ms/step - loss: 4.6740 - val_loss: 4.6550\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6713\n",
      "Epoch 00096: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6713 - val_loss: 4.6807\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6938\n",
      "Epoch 00097: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6938 - val_loss: 4.6622\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6841\n",
      "Epoch 00098: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 4.6841 - val_loss: 4.6965\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6772\n",
      "Epoch 00099: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6772 - val_loss: 4.6804\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00100: val_loss did not improve from 4.65500\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 2.2888183792701966e-08.\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6810 - val_loss: 4.6752\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6912\n",
      "Epoch 00101: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6912 - val_loss: 4.6623\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6743\n",
      "Epoch 00102: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6743 - val_loss: 4.6809\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6832\n",
      "Epoch 00103: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6832 - val_loss: 4.6933\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6890\n",
      "Epoch 00104: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6890 - val_loss: 4.6917\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6896\n",
      "Epoch 00105: val_loss did not improve from 4.65500\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.1444091896350983e-08.\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6896 - val_loss: 4.6750\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6769\n",
      "Epoch 00106: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6769 - val_loss: 4.6719\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6928\n",
      "Epoch 00107: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6928 - val_loss: 4.6862\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6860\n",
      "Epoch 00108: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6860 - val_loss: 4.6722\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6860\n",
      "Epoch 00109: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6860 - val_loss: 4.6623\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6871\n",
      "Epoch 00110: val_loss did not improve from 4.65500\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6871 - val_loss: 4.6722\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00111: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 4.6809 - val_loss: 4.6666\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6985\n",
      "Epoch 00112: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6985 - val_loss: 4.6761\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6864\n",
      "Epoch 00113: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 558ms/step - loss: 4.6864 - val_loss: 4.6615\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6788\n",
      "Epoch 00114: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6788 - val_loss: 4.6585\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6791\n",
      "Epoch 00115: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6791 - val_loss: 4.6947\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6829\n",
      "Epoch 00116: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6829 - val_loss: 4.6958\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00117: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6877 - val_loss: 4.6913\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6830\n",
      "Epoch 00118: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6830 - val_loss: 4.6779\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6860\n",
      "Epoch 00119: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6860 - val_loss: 4.6820\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6719\n",
      "Epoch 00120: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6719 - val_loss: 4.6689\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00121: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6808 - val_loss: 4.6742\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6870\n",
      "Epoch 00122: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6870 - val_loss: 4.6831\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6895\n",
      "Epoch 00123: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6895 - val_loss: 4.6852\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6704\n",
      "Epoch 00124: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 540ms/step - loss: 4.6704 - val_loss: 4.6824\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6861\n",
      "Epoch 00125: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6861 - val_loss: 4.6848\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6711\n",
      "Epoch 00126: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 4.6711 - val_loss: 4.6754\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7066\n",
      "Epoch 00127: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.7066 - val_loss: 4.6811\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6867\n",
      "Epoch 00128: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 4.6867 - val_loss: 4.6852\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6824\n",
      "Epoch 00129: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 547ms/step - loss: 4.6824 - val_loss: 4.6933\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6797\n",
      "Epoch 00130: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6797 - val_loss: 4.7119\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6922\n",
      "Epoch 00131: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6922 - val_loss: 4.6703\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6881\n",
      "Epoch 00132: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6881 - val_loss: 4.6655\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6809\n",
      "Epoch 00133: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 4.6809 - val_loss: 4.6751\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6803\n",
      "Epoch 00134: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6803 - val_loss: 4.6758\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6871\n",
      "Epoch 00135: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 4.6871 - val_loss: 4.6903\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6792\n",
      "Epoch 00136: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6792 - val_loss: 4.6763\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6898\n",
      "Epoch 00137: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6898 - val_loss: 4.6756\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6855\n",
      "Epoch 00138: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6855 - val_loss: 4.6877\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6859\n",
      "Epoch 00139: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 546ms/step - loss: 4.6859 - val_loss: 4.6719\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00140: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6810 - val_loss: 4.6665\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6655\n",
      "Epoch 00141: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6655 - val_loss: 4.6732\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6774\n",
      "Epoch 00142: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 4.6774 - val_loss: 4.6803\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6836\n",
      "Epoch 00143: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 4.6836 - val_loss: 4.6880\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6847\n",
      "Epoch 00144: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 542ms/step - loss: 4.6847 - val_loss: 4.6696\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6965\n",
      "Epoch 00145: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 4.6965 - val_loss: 4.6638\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6877\n",
      "Epoch 00146: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 543ms/step - loss: 4.6877 - val_loss: 4.6733\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6856\n",
      "Epoch 00147: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6856 - val_loss: 4.6742\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6810\n",
      "Epoch 00148: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 4.6810 - val_loss: 4.6837\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6780\n",
      "Epoch 00149: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 4.6780 - val_loss: 4.6681\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6909\n",
      "Epoch 00150: val_loss did not improve from 4.65500\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 4.6909 - val_loss: 4.6636\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=NFOLD, random_state=42,shuffle=False)\n",
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(P)):\n",
    "    print('#####################')\n",
    "    print('####### Fold %i ######'%fold)\n",
    "    print('#####################')\n",
    "    print('Training...')\n",
    "    \n",
    "    er = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-3,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    cpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='fold-%i.h5'%fold,\n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=SAVE_BEST,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    rlp = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5,\n",
    "        patience=5, \n",
    "        verbose=1, \n",
    "        min_lr=1e-8\n",
    "    )\n",
    "    model = build_model(model_class=MODEL_CLASS)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=score_loss()) \n",
    "    history = model.fit_generator(IGenerator(keys=P[tr_idx], \n",
    "                                   a = A, \n",
    "                                   tab = TAB), \n",
    "                        steps_per_epoch = 32,\n",
    "                        validation_data=IGenerator(keys=P[val_idx], \n",
    "                                   a = A, \n",
    "                                   tab = TAB),\n",
    "                        validation_steps = 16, \n",
    "                        callbacks = [cpt, rlp], \n",
    "                        epochs=EPOCHS)\n",
    "    folds_history.append(history.history)\n",
    "    print('Training done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 9.06116,
     "end_time": "2020-10-06T14:23:54.009081",
     "exception": false,
     "start_time": "2020-10-06T14:23:44.947921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-06T14:24:12.402955Z",
     "iopub.status.busy": "2020-10-06T14:24:12.391200Z",
     "iopub.status.idle": "2020-10-06T14:24:12.409777Z",
     "shell.execute_reply": "2020-10-06T14:24:12.410438Z"
    },
    "papermill": {
     "duration": 9.284905,
     "end_time": "2020-10-06T14:24:12.410646",
     "exception": false,
     "start_time": "2020-10-06T14:24:03.125741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competition Score is: 4.657088088989258\n"
     ]
    }
   ],
   "source": [
    "if SAVE_BEST:\n",
    "    mean_val_loss = np.mean([np.min(h['val_loss']) for h in folds_history])\n",
    "else:\n",
    "    mean_val_loss = np.mean([h['val_loss'][-1] for h in folds_history])\n",
    "print('Competition Score is: ' + str(mean_val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 14305.342171,
   "end_time": "2020-10-06T14:24:24.425406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-06T10:25:59.083235",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "037ed7ee7d84478ebb05d4533daa7270": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "077944019f2e44e690f7930d0e9b2f09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a28e06036beb40e88847f1c2f6c1d3f5",
        "IPY_MODEL_22820ce413414d449b74a2055d8b5427"
       ],
       "layout": "IPY_MODEL_5b39e8482ce84b3cb906e2d59822eca9"
      }
     },
     "17d5624caa39493eb853e461543974bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22820ce413414d449b74a2055d8b5427": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_980440f6aeb649948e989a1c1dd7971d",
       "placeholder": "​",
       "style": "IPY_MODEL_b8219be9f2f6459b87b231e1eafa36e4",
       "value": " 176/? [01:51&lt;00:00,  1.58it/s]"
      }
     },
     "35f964bbbf0f4acb84700fc298e7a0e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17d5624caa39493eb853e461543974bc",
       "placeholder": "​",
       "style": "IPY_MODEL_a390eb2a83344a30bd09df462b70f83f",
       "value": " 176/176 [01:50&lt;00:00,  1.59it/s]"
      }
     },
     "5b39e8482ce84b3cb906e2d59822eca9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "980440f6aeb649948e989a1c1dd7971d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a28e06036beb40e88847f1c2f6c1d3f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_037ed7ee7d84478ebb05d4533daa7270",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b820f7b6a3154fbba16d86ddb52f0ae8",
       "value": 1.0
      }
     },
     "a2a0d0411e1445d8bdad89294efb20ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a390eb2a83344a30bd09df462b70f83f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aea2384d4841468b84f90dcadff5858a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f46fc569df114510bb250250055effcb",
        "IPY_MODEL_35f964bbbf0f4acb84700fc298e7a0e4"
       ],
       "layout": "IPY_MODEL_fa58a2bb42c941febea8eb32a1de7d92"
      }
     },
     "b820f7b6a3154fbba16d86ddb52f0ae8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b8219be9f2f6459b87b231e1eafa36e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bc942f017cb04be3b5fc48c58fda1016": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f46fc569df114510bb250250055effcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc942f017cb04be3b5fc48c58fda1016",
       "max": 176.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2a0d0411e1445d8bdad89294efb20ea",
       "value": 176.0
      }
     },
     "fa58a2bb42c941febea8eb32a1de7d92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
